# 08. Virtual Memory

물리적인 메모리의 주소변환은 운영체제가 관여하지 않는다. 하지만 virtual memory는 운영체제가 관여한다.



### Demand Paging

* 요청이 있으면 그 페이지를 메모리에 올리겠다는 의미이다.
  * 디스크에서 물리적 메모리로 올리는 작업을 I/O 작업이라고 한다. 요청이 있을 때 메모리에 올리기 때문에 I/O 양이 감소하고 메모리의 사용량도 감소한다. 
  * 물리적인 메모리가 줄어들기 때문에 멀티 프로그래밍 환경에서 더 많은 프로그램, 더 많은 사용자가 동시에 메모리에 올릴 수 있기 때문에 더 효과적이다. 그리고 그로 인해 응답시간도 더 빨라진다.
    * 한정된 메모리에서 여러 프로그램이 사용되기 때문에 의미있는 정보가 메모리에 올라간다는 것은 응답시간이 더 빨라지는 것으로 볼 수 있다.
* 앞서 page table에서 Valid/Invalid bit의 의미는 valid의 경우 물리메모리에 올라갔음을 의미하고, invalid의 경우 backing storage 즉, swap 영역에 있거나 아예 사용이 되지 않음을 의미한다.
  * 요청한 페이지가 메모리에 없는 경우 = page fault이고 CPU는 자동적으로 OS에게 넘어가서 디스크에서 메모리에 올리는 작업이 일어난다.



#### Page Fault

<img src = "./img/40.png">

* Invalid page에 접근하면 MMU가 trap을 발생시킨다.
* 커널 모드로 들어가서 page fault handler가 invoke되게 되고 아래의 순서로 page fault를 처리한다.
  1. 잘못된 요청이 아닌지? 
     * 프로세스가 사용하지 않는지 혹은 protection violation인지 혹은 잘못된 주소인지 확인
  2. 물리적 메모리에 빈 페이지를 만들어야 한다. 
  3. disk에서 memory로 읽어온다
     * disk I/O가 끝나기까지 프로세스는 CPU를 뺏김 (block)
     * disk read가 끝나면 page table entry에 기록하고 valid bit에 체크
     * ready queue에 프로세스를 다시 넣고 후에 dispatch한다
  4. 프로세스가 CPU를 잡고 다시 running
  5. 아까 중단했던 instruction을 재개한다.



#### Free frame() 이 없는 경우

##### Page replacement

* 어떤 frame을 빼앗아올지 결정해야한다. 
* 운영체제가 하는 일이다. 

##### replacement algorithm

* page fault rate을 최소화하는 것이 목표이다.

* victim이 결정되었을 때,
  * 만약 희생자가 write로 새로운 내용이 적힌 경우 디스크에 반영해야함
  * 만약 변경되지 않았다면 메모리에서 삭제하면 됨

<img src = "./img/41.png">



### Algorithm

#### Optimal Algorithm

* 미래에 참조되는 페이지를 알고 있다고 가정하기 때문에 가정 최적화된 알고리즘이다. 
* 가장 먼 미래에 참조되는 page를 replace 시킨다.
* 하지만 미래를 알 수 없기 때문에 실제로 적용될 수 없다.
  * 다른 알고리즘 성능에 대한 upper bound를 제공
  * 즉, 다른 알고리즘의 성능을 평가할 때 참고할 수 있다.



#### FIFO (First In First Out) Algorithm

* FIFO : 먼저 들어온 것을 먼저 내쫓는다.
* FIFO Anomaly : frame 수가 늘어났는데 오히려 page fault가 늘어나는 현상을 말한다.

<img src = "./img/42.png">



#### LRU (Least Recently Used) Algorithm

* 가장 오래 참조된 것을 먼저 지운다.



#### LFU (Least Frequently Used) Algorithm

* 참조 횟수가 가장 적은 페이지를 지움
* 최저 참조 횟수가 여러개 있는 경우 임의로 선정한다. 하지만 성능 향상을 위해 가장 오래 전 참조된 page를 지우게 구현할 수도 있다.
* LRU처럼 직전 참조 시점만 보는 것이 아니라 장기적 시간 규모를 보기 때문에 page의 인기도를 정확하게 반영할 수 있다.
* 하지만 **참조 시점의 최근성을 반영**하지 못하고 LRU보다 구현이 복잡한 단점을 가지고 있다.

<img src = "./img/43.png">

<img src = "./img/44.png">

* LRU의 경우, 링크드 리스트로 연결해서 최신의 참조된 경우 아래로 내린다. 비교할 필요가 없기 때문에 O(1)으로 처리 가능하다.
* LFU의 경우, 링크드 리스트로 구현하면 최악의 경우 O(n)이 될 수 있기 때문에 heap 구조를 사용하게 된다. 최악의 경우 O(log n) 이 수행된다.



### caching

* 페이지 교체 알고리즘은 꼭 페이징 시스템에서 발생하는 것은아니고 cache - main memory, buffer caching, web caching 등에서 사용된다.
  * buffer - disk (file system)
* 한정된 빠른 공간(=캐쉬)에 요청된 데이터를 저장해두었다가 후속 요청시 캐쉬로부터 직접 서비스하는 방식이다.
*  교체 알고리즘에서 삭제할 항목이 지나치게 많은 시간이 걸리는 경우 실제 시스템에서 사용하지 않음
  * Buffer caching , web caching의 경우
    * O(1) ~ O(log n) 정도까지 허용
  * paging system인 경우
    * page fault가 발생하면 OS가 관여함
      * 주소변환 과정은 OS가 관여하지 않음
    * 페이지가 **이미 메모리에 존재하는 경우 OS가 관여하지 않음**. 즉, 참조시각 등의 정보를 OS가 알 수 없다. 
      * **O(1)인 LRU list 조작조차 불가능**



### Paging System에서 LRU, LFU 가능한가?

주소변환 과정에서 운영체제는 전혀 관여하지 않는다. 하지만 페이지 폴트가 발생한 경우에만 운영체제가 관여하게 된다.

즉, 주소변환 과정에서 이미 페이지가 메모리에 존재하는 경우 운영체제의 역할 없이 하드웨어적으로 작업이 완료되는 것이다. LRU 알고리즘 구현에 있어서 최근 참조했던 시간이 중요하게 되는데 이 시각의 정보를 운영체는 알 수 없게 된다.

운영체제는 맨 처음 페이지 폴트가 발생했을 때 페이지를 올린 시간은 알지만 다시 참조되는 경우의 시간을 알지 못하게 되어 **반만 알고 있는 것이 된다.**

그래서 실제 사용하는 알고리즘은 LRU, LFU를 근사시킨 **clock algorithm**을 사용하게 된다.



### Clock Algorithm

* LRU 근사 알고리즘
  * Second chance algorithm
  * NUR(Not Used Recently) 또는 NRU(Not Recently Used)
* reference bit을 사용해서 교체 대상 페이지 선정(circular list)
* referrence bit의 변환은 하드웨어가 변경해준다.
* 운영체제가 페이지 폴트로 페이지를 교체해야한다고하면, referrence bit를 확인해서
  * 만약 1이면, 0으로 바꾸고 다음 클락으로 넘어간다.
  * 만약 0이면, 페이지를 쫓겨냄
  * 즉, bit를 1로 바꾸는 것은 하드웨어가 처리하고, 0으로 바꾸는 것은 OS가 처리함 
  * 자주 사용되는 페이지라면 second chance가 왔을 때 1이다.
* Clock algorithm의 개선
  * reference bit(access bit)과 **modified bit(dirty bit)**을 함께 사용한다.
  * reference bit = 1 : 최근 참조된 페이지
  * modified bit = 1 : 최근에 변경된 페이지(I/O 동반하는 페이지)
  * 페이지에 대한 읽기만 발생했을 경우, reference bit만 1로 바뀜
  * 페이지에 대한 수정되었을 경우, reference bit, modified bit 둘 다 1로 바꾼다.
    * 쫓아낼 때 디스크에 수정을 반영되어야 하기 때문이다.



### Page Frame의 Allocation

* 프로세스에게 미리 page frame을 할당한다는 의미이다.
* Allocation의 필요성
  * 프로그램을 실행되기 위해서는 어느 정도의 page frame이 필요하다.
  * 명령어 수행을 위해 최소한 할당되어야 하는 frame 수가 있다.
  * 만약 loop를 구성하는 프로그램이 있다면, 최소한의 allocation이 없다면 매 loop마다 page fault가 발생하게 된다.
* Allocation Scheme
  * Equal allocation : 모든 프로세스에 똑같은 개수 할당
  * Proportional allocation : 프로세스 크기에 비례하여 할당
  * Priority allocation : 프로세스의 우선순위에 따라 다르게 할당
    * 프로세스가 CPU를 바로 사용할 수 있는가에 대한 ..



### Global vs Local Replacement

#### Global

* 할당 개념없이 경쟁하는 구조
* replace시 다른 프로세스에 할당된 프레임을 빼앗을 수 있다.
* 메모리를 많이 사용하는 프로그램이 메모리 독식이 발생할 수 있음
* FIFO, LRU, LFU 등의 알고리즘을 global replacement로 사용시 해당
* Working set, PFF 알고리즘 사용



#### Local

* 자신에게 할당한 frame에서만 replacement
* FIFO, LRU, LFU 등의 알고리즘을 process 별로 운영시



### Thrashing

* 메모리에 올라간 프로그램 개수가 올라갈수록 CPU의 이용률이 올라가다가 어느순간 갑자기 이용률이 뚝 떨어지는 순간이 발생한다.

<img src = "./img/45.png">

* 예를들어,

  프로세스 개수가 하나일 경우, IO를 하러간다면 CPU가 놀기 때문에 이용률이 낮다. 프로세스 개수가 두개일 경우, 하나가 IO를 하러갔다면 다른 프로세스가 CPU를 사용하기 때문에 이용률이 올라간다. 일반적으로 메모리에 프로그램이 많아질 수 록 CPU의 이용률이 올라가게 된다.

  그러다가 갑자기 CPU이 이용률이 뚝 떨어지는 경우가 발생하게 되는데 이것을 Thrashing이라고 한다.

  그 이유는 메모리에 너무 많은 프로그램이 올라가서 프로그램이 원활하게 실행되기 위해 필요한 최소한의 메모리마저 얻지 못하기 때문이다.

  각각의 프로그램이 메모리를 너무 조금 갖고 있기 때문에 CPU를 줘봐야 page fault가 계속 발생하게 된다.

  즉, CPU는 놀게 되고 page fault를 처리하는 작업(IO)이 많아지게 된다. 



#### Working set Model

* Thrashing을 방지하기 위해 등장하게 되었다.
* 적어도 locality set 부분은 보장을 해줘야지 프로세스가 원활하게 실행된다.

##### Locality of reference

* 프로세스는 특정 시간 동안 일정 장소만을 집중적으로 참조한다.
* 집중적으로 참조되는 해당 page들의 집합을 locality set이라고 한다.

##### Working set Model

* Locality의 기반하여 프로세스가 일정 시간 동안 원활하게 수행되기 위해 한꺼번에 메모리에 올라와 있어야하는 page들의 집합을 working set이라고 한다.
* Working set 모델에서는 프로세스의 **working set 전체가 메모리에 올라와있어야 수행되고 그렇지 않은 경우 모든 frame을 반납한 후 swap out(suspend)**한다.
  * 메모리가 남아돌때 suspend 되었던 것이 다시 보장받음 
* Multiprogramming degree를 결정함
* Working set의 결정
  * 과거의 어느 시간동안 사용한 페이지 몇 개를 유지함.
  * 과거를 통해서 추정한다.
  * 현재 시점부터 과거의 delta 크기만큼 window를 지정하고 움직인다.
  * 중복된 것은 제외!! 델타 크기만큼 사용된 페이지가 중복제거 2개뿐일 경우 working set은 2개이다.

<img src = "./img/46.png">

* 결국 Global, Local replacement를 혼합한 것임.



### PFF (Page Fault Frequency) Scheme

* frame의 수가 많을 수록 page fault rate는 줄어든다. 하지만 frame의 수가 늘어나도 fault의 수가 완전히 사라지지 않기 때문에 page fault rate의 상한값과 하한값을 둔다.

<img src = "./img/47.png">

* 어떤 프로세스의 page fault rate이 높으면 frame을 더 할당한다.
* 어떤 프로세스의 page fault rate이 낮으면 frame을 빼앗는다.
* 만약 빈 frame이 없으면 일부 프로세스를 swap out한다.



### Page Size 결정

* 요즘 추세 : 메모리 크기가 커지고 프로그램도 커지다보니 메모리에 들어가는 페이지 수가 점점 늘어나게 된다. 그래서 Larger Page size가 추세임.(보통 4KB)
* 만약 페이지 사이즈를 줄이게 되면? 즉, 페이지의 개수가 많아지면...
  * 페이지 테이블의 entry가 그만큼 늘어난다.
  * 불필요하게 낭비되는 메모리 공간은 줄어들 수 있다. (내부조각 줄어듬)
  * 메모리가 사용될 때 인접한 위치가 사용될 가능성이 있다. 같이 즉, 어느정도 크기만큼 메모리로 읽어왔으면 page fault가 발생하지 않지만 페이지 사이즈가 줄어들면 그 만큼 page fault가 발생할 가능성이 높아지기 때문에 disk transfer의 효율성이 감소한다.
  * 즉, 필요한 정보만 메모리에 올라오면 메모리 이용이 효율적이지만 Locality의 활용 측면에서는 좋지 않다.

